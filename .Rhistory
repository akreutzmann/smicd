if (inverse==TRUE){
trans_dat <- Box(lambda, y=dat$pseudoy , inv = TRUE, m=m)$y
}
}
if (is.data.frame(dat)==FALSE) {
if (inverse==FALSE){
trans_dat <- Box(lambda, y = dat, inv=FALSE)$y
m <- Box(lambda, y = dat, inv=FALSE)$m
}
if (inverse==TRUE){
trans_dat <- Box(lambda, y=dat , inv = TRUE, m=m)$y
}
}
res <- list(trans_dat, m, lambda_new)
return(res)
}
lambda <- lambda.est$lambda
if (trafo=="bc") {suppressWarnings(lambda.est <-
lambda.lme.est(formula = formula,
data = data,
classes = classes,
burnin = burnin,
samples = samples,
adjust = adjust))
lambda <- lambda.est$lambda
result_lambda <- lambda.est$it.lambda
b.lambda <- lambda.est$b.lambda
m.lambda <- lambda.est$m.lambda
BoxCoxClasses <- boxcox.lme.est(dat=classes,lambda = lambda,  inverse=FALSE)
classes <- BoxCoxClasses[[1]]
}
data <- midpoints.est(formula = formula, data = data, classes = classes)
formula <- as.formula(gsub(".*~","pseudoy~",formula))
regclass <- lmer(formula,data=data)
resulty <- matrix(ncol = c(burnin + samples), nrow = nrow(data))
resultcoef <- matrix(ncol = c(burnin + samples), nrow = length(regclass@beta))
result_ranef <- vector("list", burnin + samples)
result_sigmae<-vector(mode = "numeric", length = burnin+samples)
result_r2c<-vector(mode = "numeric", length = burnin+samples)
result_r2m<-vector(mode = "numeric", length = burnin+samples)
result_icc <- vector(mode = "numeric", length = burnin+samples)
VaCovMa <- vector("list", burnin+samples)
for (j in 1:(burnin + samples)) {
data$predict <- predict(regclass,data)
sigmahat <- sigma(regclass)
for (i in 1:(length(classes) - 1)) {
if (nrow(data[data$yclassl==i,])!=0) {
mean <- data$predict[data$yclassl==i]
pseudoy <- rtruncnorm(length(mean), a=classes[i], b=classes[i+1], mean=mean, sd=sigmahat )
data$pseudoy[data$yclassl==i] <- pseudoy
}
}
regclass=lmer(formula,data=data )
resultcoef[,j] <- regclass@beta
result_ranef[[j]] <- as.matrix(ranef(regclass)[[1]])
result_sigmae[j]<- sigmahat
#result_sigmau[j]<-as.data.frame(VarCorr(regclass))$sdcor[1]
result_r2m[j] <- unname(r.squaredGLMM(regclass)[1])
result_r2c[j] <- unname(r.squaredGLMM(regclass)[2])
result_icc[j] <- icc.est(model = regclass)
resulty[,j] <- data$pseudoy
VaCovMa[[j]] <- as.matrix(unclass(VarCorr(regclass))[[1]][1:ncol(ranef(regclass)[[1]]),])
}
parameter.ma <- list(ranef = result_ranef, VaCov = VaCovMa)
parameter.final.ma <- parameters.est.ma(parameter = parameter.ma, burnin = burnin)
colnames(parameter.final.ma$VaCov) <- colnames(VaCovMa[[1]])
rownames(parameter.final.ma$VaCov) <- rownames(VaCovMa[[1]])
colnames(parameter.final.ma$ranef) <- colnames(result_ranef[[1]])
parameter <- list(coef = resultcoef,
sigmae = result_sigmae,
r2m = result_r2m, r2c = result_r2c,
icc = result_icc)
parameter.final <- parameters.est(parameter = parameter, burnin = burnin)
names(parameter.final$coef) <- rownames(summary(regclass)$coefficients)
formula = o.formula
data = o.data
classes = o.classes
coef = parameter.final$coef
sigmae = parameter.final$sigmae
VaCov = parameter.final.ma$VaCov
nameRI = names(ranef(regclass))
nameRS = names(ranef(regclass)[[1]])[2]
regmodell = regclass
lambda = m.lambda
# Fixed effect prediction to find mu
boot_data <- data
fixedformula <- as.formula(lme4::nobars(formula(regmodell))[-2])
fixedeffect <- model.matrix(fixedformula,data = boot_data)
mu <- as.matrix(fixedeffect) %*% coef
# Get names from FE
name.fe <- names(coef)
# Get name from random intercept
name.RI <- nameRI
# Get name from random  slope
name.RS <- nameRS
# Get name of dependent variable from formula
name.dep <- all.vars(formula)[1]
coef <- NULL
pb <- txtProgressBar(min = 1, max = b, style = 3)
i<-1
p.ranef <- NULL
for (j in 1 :length(unique(boot_data[,tail(all.vars(formula), n=1)]))){
p.ranef <- rbind(p.ranef, apply(rmvnorm(n = 1, mean = rep(0, nrow(VaCov))
,sigma = VaCov), 2,
function(x) {rep(x,table(boot_data[,tail(all.vars(formula), n=1)])[j])}))
}
if(is.na(nameRS)) {boot_data$ynew <- mu + p.ranef[,1] + rnorm(nrow(boot_data), 0 , sigmae)}
if(!is.na(nameRS)) {boot_data$ynew <- mu + p.ranef[,1] + p.ranef[,2]*boot_data[,name.RS]+
rnorm(nrow(boot_data), 0 , sigmae)}
head(boot_data$ynew)
hist(boot_data)
hist(boot_data$ynew)
summary(boot_data$ynew)
rueck <- boxcox.lme.est(dat=boot_data$ynew, lambda = lambda, inverse = T)
str(rueck)
nrow(boot_data)
rueck[[1]]
boot_data$ynew <- rueck[[1]]
##
boot_data$ynew[boot_data$ynew<classes[1]] <- classes[1]+.Machine$double.eps
boot_data$ynew[boot_data$ynew>classes[length(classes)]] <-
classes[length(classes)]+.Machine$double.eps
hist(boot_data$ynew)
assign(paste0("boot_data$",name.dep), cut(boot_data$ynew, classes))
capture.output(SEM <- semLme(formula = formula, data = boot_data,
classes = classes, burnin = burnin, samples = samples,
trafo = trafo, adjust = adjust, bootstrap.se = FALSE))
coef <- rbind(coef, SEM$coef)
coef
library(smicd)
# Run model with random intercept and default settings
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
model1 <- semLme(formula = examsc.class ~ standLRT + schavg + (1|school),
data = data, classes = classes, burnin = 2, samples = 4, bootstrap.se = TRUE, b = 50, trafo = "bc")
summary(model1)
help("semLme")
model1 <- semLme(formula = examsc.class ~ standLRT + schavg + (standLRT|school),
data = data, classes = classes, burnin = 2, samples = 4, bootstrap.se = TRUE, b = 50, trafo = "bc")
summary(model1)
library(smicd)
help(ICD)
devtools::use_travis()
devtools::release()
devtools::release()
check()
devtools::install()
installed.packages("spatstat")
install.packages("spatstat")
install.packages("spatstat")
library(sparstat)
library(spatstat)
devtools::install()
devtools::use_vignette("smicd")
devtools::release()
3
devtools::release()
R.Version()
revdep_check()
devtools::revdep_check()
checks <- readRDS("H:/ICD/revdep/checks.rds")
checks
devtools::release()
use_cran_comments
use_cran_comments()
install.packages("pandoc")
use_cran_comments()
devtools::release()
library(KernSmooth)
toBibtex(KernSmooth)
toBibtex(citation("KernSmooth"))
help(ICD)
library(ICD)
help(ICD)
library(smicd)
library(smicd)
help("semLm")
help("semLme")
help("kdeAlgo")
devtools::release()
library(installr)
install.pandoc()
library(pandoc)
install.pandoc()
install.pandoc()
devtools::release()
devtools::release()
devtools::release()
library("ggplot2")
library("dlstats")
x <- cran_stats(c("emojifont", "ggimage", "hexSticker", "rvcheck"))
head(x)
ggplot(x, aes(end, downloads, group=package, color=package)) +
geom_line() + geom_point(aes(shape=package))
x <- cran_stats(c("emdi", "Kernelheaping", "smicd"))
ggplot(x, aes(end, downloads, group=package, color=package)) +
geom_line() + geom_point(aes(shape=package))
x <- cran_stats(c("emdi", "Kernelheaping", "smicd", "laeken"))
ggplot(x, aes(end, downloads, group=package, color=package)) +
geom_line() + geom_point(aes(shape=package))
x <- cran_stats(c("emdi", "Kernelheaping", "smicd", "saeRobust", "saeSim"))
ggplot(x, aes(end, downloads, group=package, color=package)) +
geom_line() + geom_point(aes(shape=package))
toBibtex(citation("intReg"))
load("H:/Doktor2/R-Code/GeneralMixedModel/Data/Intercept_6Classes_N.RData")
data <- Pop[[1]]
table(data$yclass)
sum(table(data$yclass))
str(table(data$yclass))
unname(table(data$yclass))
dat <- unname(table(data$yclass))
names(table(data$yclass))
names(dat) <- names(table(data$yclass))
dat
?xtable
??xtable
library(xtable)
xtable(table(data$yclass))
# Normal, 12 classes
load("H:/Doktor2/R-Code/GeneralMixedModel/Data/Intercept_12Classes_N.RData")
data <- Pop[[1]]
xtable(table(data$yclass))
# Normal, 24 classes
load("H:/Doktor2/R-Code/GeneralMixedModel/Data/Intercept_24Classes_N.RData")
data <- Pop[[1]]
xtable(table(data$yclass))
# Log, 12 classes
load("H:/Doktor2/R-Code/GeneralMixedModel/Data/Intercept_12Classes_Log.RData")
data <- Pop[[1]]
xtable(table(data$yclass))
# 12 classes interval + slope
load("H:/Doktor2/R-Code/GeneralMixedModel/Data/InterceptSlope_12Classes_N.RData")
data <- Pop[[1]]
xtable(table(data$yclass))
data <- Pop[[2]]
xtable(table(data$yclass))
library(smicd)
help(semLME)
help(semLme)
## Not run:
# Load and prepare data
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
# Run model with random intercept and default settings
model1 <- semLme(formula = examsc.class ~ standLRT + schavg + (1|school),
data = data, classes = classes)
summary(model1)
# Run model with random intercept + random slope with default settings
model2 <- semLme(formula = examsc.class ~ standLRT + schavg +
(standLRT|school), data = data, classes = classes, burnin = 5,
samples = 20)
summary(model2)
print(model2)
plot(model2)
# Run model with random intercept + random slope with default settings
model2 <- semLme(formula = examsc.class ~ standLRT + schavg +
(standLRT|school), data = data, classes = classes, burnin = 5,
samples = 20, trafo = "log")
summary(model2)
help("kdeAlgo")
library(smicd)
help("kdeAlgo")
help(smicd)
library(smicd)
libr
library(smicd)
help(smicd)
remove.packages("smicd")
library(smicd)
help("kdeAlgo")
remove.packages("smicd")
library(smicd)
help("kdeAlgo")
remove.packages("smicd")
library(smicd)
help(smicd)
remove.packages("smicd")
library(smicd)
help(smicd)
help("smicd")
remove.packages("smicd")
library(smicd)
help(smicd)
help(smicd)
library(help=smicd
)
log(0)
remove.packages("smicd")
library(smicd)
help(smicd)
remove.packages("smicd")
#' Statistical Methods for Interval Censored (Grouped) Data
#'
#' The package \pkg{smicd} supports the estimation of linear and linear mixed regression
#' models (random slope and random intercept models)
#' with interval censored dependent variable. Parameter estimates are obtain
#' by a stochastic expectation maximization (SEM) algorithm (\cite{Walter et al., 2017}).
#' Standard errors are estimated by a non-parametric bootstrap in the linear
#' regression model and by a parametric bootstrap in the linear mixed regression
#' model. To handle departures
#' from the model assumptions transformations (log and Box-Cox) of the interval censored
#' dependent variable are incorporated into
#' the algorithm (\cite{Walter et al., 2017}). Furthermore, the package \pkg{smicd} has
#' implemented a non-parametric kernel density algorithm for the direct (without
#' covariates) estimation of statistical indicators from interval censored data
#' (\cite{Walter and Weimer, 2018}; \cite{Gross et al., 2017}). The standard
#' errors of the statistical indicators
#' are estimated by a non-parametric bootstrap.
#'
#' @details
#' The two estimation functions for the linear and linear mixed regression model
library(smicd)
help(smicd)
## Not run:
# Load and prepare data
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
# Run model with random intercept and default settings
model1 <- semLme(formula = examsc.class ~ standLRT + schavg + (1|school),
data = data, classes = classes)
summary(model1)
model1
str(model1)
library(smicd)
remove.packages("MuMIn")
install.packages("MuMIn")
install.packages("MuMIn")
library(smicd)
## Not run:
# Load and prepare data
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
# Run model with random intercept + random slope with default settings
model2 <- semLme(formula = examsc.class ~ standLRT + schavg +
(standLRT|school), data = data, classes = classes, burnin = 5,
samples = 20, trafo = "log")
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
formula = examsc.class ~ standLRT + schavg +
(standLRT|school)
burnin = 5
samples = 20
trafo = "None"
adjust = 2
bootstrap.se = FALSE
b = 100
save.image("C:/Users/paulwalter/Desktop/rsquard.RData")
call <- match.call()
o.classes = classes
o.data = data
o.formula = formula
lambda <- result_lambda <- b.lambda <- m.lambda <- se <- ci <- NULL
if (trafo=="log"){classes <- log.est(y = classes)}
if (trafo=="bc") {suppressWarnings(lambda.est <-
lambda.lme.est(formula = formula,
data = data,
classes = classes,
burnin = burnin,
samples = samples,
adjust = adjust))
lambda <- lambda.est$lambda
result_lambda <- lambda.est$it.lambda
b.lambda <- lambda.est$b.lambda
m.lambda <- lambda.est$m.lambda
BoxCoxClasses <- boxcox.lme.est(dat=classes,lambda = lambda,  inverse=FALSE)
classes <- BoxCoxClasses[[1]]
}
data <- midpoints.est(formula = formula, data = data, classes = classes)
formula <- as.formula(gsub(".*~","pseudoy~",formula))
# Internal documentation -------------------------------------------------------
# The function estimates the interval midpoints
midpoints.est <- function(formula, data, classes) {
model_frame <- model.frame(formula, data = data)
yclass <- model.response(model_frame)
yclassl <- model.response(model_frame)
levels(yclassl) <- 1:length(levels(yclassl))
yclassl <- as.numeric(as.vector(yclassl))
data$yclassl <- yclassl
intervals <- vector("list", length(classes) -  1)
for (i in seq(length = length(classes) - 1)) {
intervals[[i]] <- c(classes[i], classes[i +1])
}
means <- sapply(intervals, mean)
widths <- sapply(intervals, function(x) x[2] - x[1])
meanWidth <- mean(widths[!is.infinite(widths)])
negInf <- is.infinite(means) & means < 0
if (any(negInf)) {
means[negInf] <- sapply(intervals[negInf], function(x) (x[2] +  (x[2]-
meanWidth))/2)
}
posInf <- is.infinite(means) & means > 0
if (any(posInf)) {
means[posInf] <- sapply(intervals[posInf], function(x) (x[1]+(x[1] +
meanWidth))/2)
}
yclassmeans<-means
levels(yclass) <- yclassmeans
data$pseudoy <- as.numeric(as.vector(yclass))
return(data)
}
data <- midpoints.est(formula = formula, data = data, classes = classes)
formula
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
formula = examsc.class ~ standLRT + schavg + (1|school)
call <- match.call()
o.classes = classes
o.data = data
o.formula = formula
lambda <- result_lambda <- b.lambda <- m.lambda <- se <- ci <- NULL
if (trafo=="log"){classes <- log.est(y = classes)}
if (trafo=="bc") {suppressWarnings(lambda.est <-
lambda.lme.est(formula = formula,
data = data,
classes = classes,
burnin = burnin,
samples = samples,
adjust = adjust))
lambda <- lambda.est$lambda
result_lambda <- lambda.est$it.lambda
b.lambda <- lambda.est$b.lambda
m.lambda <- lambda.est$m.lambda
BoxCoxClasses <- boxcox.lme.est(dat=classes,lambda = lambda,  inverse=FALSE)
classes <- BoxCoxClasses[[1]]
}
data <- midpoints.est(formula = formula, data = data, classes = classes)
formula <- as.formula(gsub(".*~","pseudoy~",formula))
regclass <- lmer(formula,data=data)
library(lmer)
library(lme4)
regclass <- lmer(formula,data=data)
resulty <- matrix(ncol = c(burnin + samples), nrow = nrow(data))
resultcoef <- matrix(ncol = c(burnin + samples), nrow = length(regclass@beta))
result_ranef <- vector("list", burnin + samples)
result_sigmae<-vector(mode = "numeric", length = burnin+samples)
result_r2c<-vector(mode = "numeric", length = burnin+samples)
result_r2m<-vector(mode = "numeric", length = burnin+samples)
result_icc <- vector(mode = "numeric", length = burnin+samples)
VaCovMa <- vector("list", burnin+samples)
j<-1
data$predict <- predict(regclass,data)
sigmahat <- sigma(regclass)
for (i in 1:(length(classes) - 1)) {
if (nrow(data[data$yclassl==i,])!=0) {
mean <- data$predict[data$yclassl==i]
pseudoy <- rtruncnorm(length(mean), a=classes[i], b=classes[i+1], mean=mean, sd=sigmahat )
data$pseudoy[data$yclassl==i] <- pseudoy
}
}
library(truncnorm)
for (i in 1:(length(classes) - 1)) {
if (nrow(data[data$yclassl==i,])!=0) {
mean <- data$predict[data$yclassl==i]
pseudoy <- rtruncnorm(length(mean), a=classes[i], b=classes[i+1], mean=mean, sd=sigmahat )
data$pseudoy[data$yclassl==i] <- pseudoy
}
}
regclass=lmer(formula,data=data )
resultcoef[,j] <- regclass@beta
result_ranef[[j]] <- as.matrix(ranef(regclass)[[1]])
result_sigmae[j]<- sigmahat
r_squared <- r.squaredGLMM(regclass)
library(MuMin)
library(MuMIn)
r_squared <- r.squaredGLMM(regclass)
r_squared
is.matrix(r_squared)
unname(r_squared["delta", 1])
unname(r_squared[1, 1])
unname(r_squared[1, 2])
library(smicd)
## Not run:
# Load and prepare data
data <- Exam
classes <- c(1,1.5,2.5,3.5,4.5,5.5,6.5,7.7,8.5, Inf)
data$examsc.class<- cut(data$examsc, classes)
# Run model with random intercept and default settings
model1 <- semLme(formula = examsc.class ~ standLRT + schavg + (1|school),
data = data, classes = classes)
summary(model1)
# Run model with random intercept + random slope with default settings
model2 <- semLme(formula = examsc.class ~ standLRT + schavg +
(standLRT|school), data = data, classes = classes, burnin = 5,
samples = 20, trafo = "log")
summary(model2)
library(smicd)
help("semLm")
help(Exam)
library(smicd)
help("smicd")
Nora <- 66
Paul <- 66
AK <- 20
Soeren <- 33
Nora+Paul+AK+Soeren
N <- 25
P <- 66
F <- 66
S <- 15
AK <- 75
N+P+F+S+AK
N <- 25
P <- 66
F <- 66
S <- 15
N+P+F+S
